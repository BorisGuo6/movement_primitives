<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>movement_primitives.data API documentation</title>
<meta name="description" content="Tools for loading datasets." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>movement_primitives.data</code></h1>
</header>
<section id="section-intro">
<p>Tools for loading datasets.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Tools for loading datasets.&#34;&#34;&#34;
from ._lasa import load_lasa
from ._minimum_jerk import generate_minimum_jerk
from ._toy_1d import generate_1d_trajectory_distribution


__all__ = [
    &#34;load_lasa&#34;,
    &#34;generate_minimum_jerk&#34;,
    &#34;generate_1d_trajectory_distribution&#34;]


try:
    from ._mocap import (
        smooth_dual_arm_trajectories_pq, smooth_single_arm_trajectories_pq,
        transpose_dataset, load_mia_demo, load_kuka_demo, load_rh5_demo,
        load_kuka_dataset)
    mocap_available = True
except ImportError:
    mocap_available = False
    import warnings
    warnings.warn(&#34;mocap library is not available&#34;)


__all__ += [
    &#34;smooth_dual_arm_trajectories_pq&#34;, &#34;smooth_single_arm_trajectories_pq&#34;,
    &#34;load_mia_demo&#34;, &#34;load_kuka_demo&#34;, &#34;load_rh5_demo&#34;,
    &#34;load_kuka_dataset&#34;]</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="movement_primitives.data.generate_1d_trajectory_distribution"><code class="name flex">
<span>def <span class="ident">generate_1d_trajectory_distribution</span></span>(<span>n_demos, n_steps, initial_offset_range=3.0, final_offset_range=0.1, noise_per_step_range=20.0, random_state=RandomState(MT19937))</span>
</code></dt>
<dd>
<div class="desc"><p>Generates toy data for testing and demonstration.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>n_demos</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of demonstrations</dd>
<dt><strong><code>n_steps</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of steps</dd>
<dt><strong><code>initial_offset_range</code></strong> :&ensp;<code>float</code>, optional <code>(default: 3)</code></dt>
<dd>Range of initial offset from cosine</dd>
<dt><strong><code>final_offset_range</code></strong> :&ensp;<code>float</code>, optional <code>(default: 0.1)</code></dt>
<dd>Range of final offset from cosine</dd>
<dt><strong><code>noise_per_step_range</code></strong> :&ensp;<code>float</code>, optional <code>(default: 20)</code></dt>
<dd>Factor for noise in each step</dd>
<dt><strong><code>random_state</code></strong> :&ensp;<code>RandomState</code>, optional <code>(default: seed 0)</code></dt>
<dd>Random state</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>T</code></strong> :&ensp;<code>array, shape (n_steps,)</code></dt>
<dd>Times</dd>
<dt><strong><code>Y</code></strong> :&ensp;<code>array, shape (n_demos, n_steps, 1)</code></dt>
<dd>Demonstrations (positions)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_1d_trajectory_distribution(
        n_demos, n_steps, initial_offset_range=3.0, final_offset_range=0.1,
        noise_per_step_range=20.0, random_state=np.random.RandomState(0)):
    &#34;&#34;&#34;Generates toy data for testing and demonstration.

    Parameters
    ----------
    n_demos : int
        Number of demonstrations

    n_steps : int
        Number of steps

    initial_offset_range : float, optional (default: 3)
        Range of initial offset from cosine

    final_offset_range : float, optional (default: 0.1)
        Range of final offset from cosine

    noise_per_step_range : float, optional (default: 20)
        Factor for noise in each step

    random_state : RandomState, optional (default: seed 0)
        Random state

    Returns
    -------
    T : array, shape (n_steps,)
        Times

    Y : array, shape (n_demos, n_steps, 1)
        Demonstrations (positions)
    &#34;&#34;&#34;
    T = np.linspace(0, 1, n_steps)
    Y = np.empty((n_demos, n_steps, 1))

    A = create_finite_differences_matrix_1d(n_steps, dt=1.0 / (n_steps - 1))
    cov = np.linalg.inv(A.T.dot(A))
    L = np.linalg.cholesky(cov)

    for demo_idx in range(n_demos):
        Y[demo_idx, :, 0] = np.cos(2 * np.pi * T)
        if initial_offset_range or final_offset_range:
            initial_offset = initial_offset_range * (random_state.rand() - 0.5)
            final_offset = final_offset_range * (random_state.rand() - 0.5)
            Y[demo_idx, :, 0] += np.linspace(
                initial_offset, final_offset, n_steps)
        if noise_per_step_range:
            noise_per_step = (noise_per_step_range
                              * L.dot(random_state.randn(n_steps)))
            Y[demo_idx, :, 0] += noise_per_step
    return T, Y</code></pre>
</details>
</dd>
<dt id="movement_primitives.data.generate_minimum_jerk"><code class="name flex">
<span>def <span class="ident">generate_minimum_jerk</span></span>(<span>start, goal, execution_time=1.0, dt=0.01)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a minimum jerk trajectory.</p>
<p>A minimum jerk trajectory from :math:<code>x_0</code> to :math:<code>g</code> minimizes
the third time derivative of the positions:</p>
<p>[ \arg \min_{x_0, \ldots, x_T} \int_{t=0}^T \dddot{x}(t)^2 dt ]
The trajectory will have</p>
<p>.. code-block:: python</p>
<pre><code>n_steps = 1 + execution_time / dt
</code></pre>
<p>steps because we start at 0 seconds and end at execution_time seconds.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>start</code></strong> :&ensp;<code>array-like, shape (n_dims,)</code></dt>
<dd>Initial state</dd>
<dt><strong><code>goal</code></strong> :&ensp;<code>array-like, shape (n_dims,)</code></dt>
<dd>Goal</dd>
<dt><strong><code>execution_time</code></strong> :&ensp;<code>float</code>, optional <code>(default: 1)</code></dt>
<dd>Execution time in seconds</dd>
<dt><strong><code>dt</code></strong> :&ensp;<code>float</code>, optional <code>(default: 0.01)</code></dt>
<dd>Time between successive steps in seconds</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>array, shape (n_dims, n_steps)</code></dt>
<dd>The positions of the trajectory</dd>
<dt><strong><code>Xd</code></strong> :&ensp;<code>array, shape (n_dims, n_steps)</code></dt>
<dd>The velocities of the trajectory</dd>
<dt><strong><code>Xdd</code></strong> :&ensp;<code>array, shape (n_task_dims, n_steps)</code></dt>
<dd>The accelerations of the trajectory</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_minimum_jerk(start, goal, execution_time=1.0, dt=0.01):
    &#34;&#34;&#34;Create a minimum jerk trajectory.

    A minimum jerk trajectory from :math:`x_0` to :math:`g` minimizes
    the third time derivative of the positions:

    .. math::

        \\arg \min_{x_0, \ldots, x_T} \int_{t=0}^T \dddot{x}(t)^2 dt

    The trajectory will have

    .. code-block:: python

        n_steps = 1 + execution_time / dt

    steps because we start at 0 seconds and end at execution_time seconds.

    Parameters
    ----------
    start : array-like, shape (n_dims,)
        Initial state

    goal : array-like, shape (n_dims,)
        Goal

    execution_time : float, optional (default: 1)
        Execution time in seconds

    dt : float, optional (default: 0.01)
        Time between successive steps in seconds

    Returns
    -------
    X : array, shape (n_dims, n_steps)
        The positions of the trajectory

    Xd : array, shape (n_dims, n_steps)
        The velocities of the trajectory

    Xdd : array, shape (n_task_dims, n_steps)
        The accelerations of the trajectory
    &#34;&#34;&#34;
    x0 = np.asarray(start)
    g = np.asarray(goal)
    if x0.shape != g.shape:
        raise ValueError(&#34;Shape of initial state %s and goal %s must be equal&#34;
                         % (x0.shape, g.shape))

    n_task_dims = x0.shape[0]
    n_steps = 1 + int(execution_time / dt)

    X = np.zeros((n_task_dims, n_steps))
    Xd = np.zeros((n_task_dims, n_steps))
    Xdd = np.zeros((n_task_dims, n_steps))

    x = x0.copy()
    xd = np.zeros(n_task_dims)
    xdd = np.zeros(n_task_dims)

    X[:, 0] = x
    for t in range(1, n_steps):
        tau = execution_time - t * dt

        if tau &gt;= dt:
            dist = g - x

            a1 = 0
            a0 = xdd * tau ** 2
            v1 = 0
            v0 = xd * tau

            t1 = dt
            t2 = dt ** 2
            t3 = dt ** 3
            t4 = dt ** 4
            t5 = dt ** 5

            c1 = (6. * dist + (a1 - a0) / 2. - 3. * (v0 + v1)) / tau ** 5
            c2 = (-15. * dist + (3. * a0 - 2. * a1) / 2. + 8. * v0 +
                  7. * v1) / tau ** 4
            c3 = (10. * dist + (a1 - 3. * a0) / 2. - 6. * v0 -
                  4. * v1) / tau ** 3
            c4 = xdd / 2.
            c5 = xd
            c6 = x

            x = c1 * t5 + c2 * t4 + c3 * t3 + c4 * t2 + c5 * t1 + c6
            xd = (5. * c1 * t4 + 4 * c2 * t3 + 3 * c3 * t2 + 2 * c4 * t1 + c5)
            xdd = (20. * c1 * t3 + 12. * c2 * t2 + 6. * c3 * t1 + 2. * c4)

        X[:, t] = x
        Xd[:, t] = xd
        Xdd[:, t] = xdd

    return X, Xd, Xdd</code></pre>
</details>
</dd>
<dt id="movement_primitives.data.load_kuka_dataset"><code class="name flex">
<span>def <span class="ident">load_kuka_dataset</span></span>(<span>pattern, context_names=None, verbose=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Load dataset obtained from kinesthetic teaching of dual arm Kuka system.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>pattern</code></strong> :&ensp;<code>str</code></dt>
<dd>Pattern that defines csv files that should be loaded, e.g., *.csv</dd>
<dt><strong><code>context_names</code></strong> :&ensp;<code>list</code>, optional <code>(default: None)</code></dt>
<dd>Contexts that should be loaded</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code>, optional <code>(default: 0)</code></dt>
<dd>Verbosity level</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>dataset</code></strong> :&ensp;<code>list</code> of <code>tuples</code></dt>
<dd>Each entry contains either an array of time (T, shape (n_steps,)),
the dual arm trajectories (P, shape (n_steps, 14)) represented by
positions of the left arm, orientation quaternion of the left arm,
positions of the right arm, and the orientation quaternion of the
right arm, or T, P, and the context (shape, (n_context_dims,)).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_kuka_dataset(pattern, context_names=None, verbose=0):
    &#34;&#34;&#34;Load dataset obtained from kinesthetic teaching of dual arm Kuka system.

    Parameters
    ----------
    pattern : str
        Pattern that defines csv files that should be loaded, e.g., *.csv

    context_names : list, optional (default: None)
        Contexts that should be loaded

    verbose : int, optional (default: 0)
        Verbosity level

    Returns
    -------
    dataset : list of tuples
        Each entry contains either an array of time (T, shape (n_steps,)),
        the dual arm trajectories (P, shape (n_steps, 14)) represented by
        positions of the left arm, orientation quaternion of the left arm,
        positions of the right arm, and the orientation quaternion of the
        right arm, or T, P, and the context (shape, (n_context_dims,)).
    &#34;&#34;&#34;
    filenames = list(glob.glob(pattern))
    if verbose:
        print(&#34;Loading dataset...&#34;)
        filenames = tqdm(filenames)
    return [load_kuka_demo(f, context_names, verbose=verbose)
            for f in filenames]</code></pre>
</details>
</dd>
<dt id="movement_primitives.data.load_kuka_demo"><code class="name flex">
<span>def <span class="ident">load_kuka_demo</span></span>(<span>filename, context_names=None, verbose=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Load a single demonstration from the dual arm Kuka system from csv.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the csv file.</dd>
<dt><strong><code>context_names</code></strong> :&ensp;<code>list</code>, optional <code>(default: None)</code></dt>
<dd>Name of context variables that should be loaded.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code>, optional <code>(default: 0)</code></dt>
<dd>Verbosity level</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>T</code></strong> :&ensp;<code>array, shape (n_steps,)</code></dt>
<dd>Time steps</dd>
<dt><strong><code>P</code></strong> :&ensp;<code>array, shape (n_steps, 14)</code></dt>
<dd>Dual arm trajectories represented by position of the left arm,
orientation quaternion of the left arm, position of the right arm,
and orientation quaternion of the right arm.</dd>
<dt><strong><code>context</code></strong> :&ensp;<code>array, shape (len(context_names),)</code>, optional</dt>
<dd>Values of context variables. These will only be returned if
context_names are given.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_kuka_demo(filename, context_names=None, verbose=0):
    &#34;&#34;&#34;Load a single demonstration from the dual arm Kuka system from csv.

    Parameters
    ----------
    filename : str
        Name of the csv file.

    context_names : list, optional (default: None)
        Name of context variables that should be loaded.

    verbose : int, optional (default: 0)
        Verbosity level

    Returns
    -------
    T : array, shape (n_steps,)
        Time steps

    P : array, shape (n_steps, 14)
        Dual arm trajectories represented by position of the left arm,
        orientation quaternion of the left arm, position of the right arm,
        and orientation quaternion of the right arm.

    context : array, shape (len(context_names),), optional
        Values of context variables. These will only be returned if
        context_names are given.
    &#34;&#34;&#34;
    if verbose:
        tqdm.write(&#34;Loading &#39;%s&#39;&#34; % filename)
    trajectory = pd.read_csv(filename, sep=&#34; &#34;)

    if context_names is not None:
        context = trajectory[list(context_names)].iloc[0].to_numpy()
        if verbose:
            tqdm.write(&#34;Context: %s&#34; % (context,))

    PREFIX_LEFT = &#34;kuka_lbr_cart_pos_ctrl_left\.current_feedback\.pose\.&#34;
    PREFIX_RIGHT = &#34;kuka_lbr_cart_pos_ctrl_right\.current_feedback\.pose\.&#34;
    patterns = [
        &#34;time\.microseconds&#34;,
        f&#34;{PREFIX_LEFT}position\.data.*&#34;,
        f&#34;{PREFIX_LEFT}orientation\.re.*&#34;,
        f&#34;{PREFIX_LEFT}orientation\.im.*&#34;,
        f&#34;{PREFIX_RIGHT}position\.data.*&#34;,
        f&#34;{PREFIX_RIGHT}orientation\.re.*&#34;,
        f&#34;{PREFIX_RIGHT}orientation\.im.*&#34;]
    columns = mocap.pandas_utils.match_columns(trajectory, patterns)
    trajectory = trajectory[columns]

    group_rename = {
        &#34;(time\.microseconds)&#34;: &#34;Time&#34;,
        f&#34;({PREFIX_LEFT}position\.data).*&#34;: &#34;left_pose&#34;,
        f&#34;({PREFIX_LEFT}orientation).*&#34;: &#34;left_pose&#34;,
        f&#34;({PREFIX_RIGHT}position\.data).*&#34;: &#34;right_pose&#34;,
        f&#34;({PREFIX_RIGHT}orientation).*&#34;: &#34;right_pose&#34;
    }
    trajectory = mocap.pandas_utils.rename_stream_groups(trajectory, group_rename)

    trajectory[&#34;Time&#34;] = trajectory[&#34;Time&#34;] / 1e6
    trajectory[&#34;Time&#34;] -= trajectory[&#34;Time&#34;].iloc[0]
    T = trajectory[&#34;Time&#34;].to_numpy()

    P = mocap.array_from_dataframe(
        trajectory,
        [&#34;left_pose[0]&#34;, &#34;left_pose[1]&#34;, &#34;left_pose[2]&#34;, &#34;left_pose.re&#34;,
         &#34;left_pose.im[0]&#34;, &#34;left_pose.im[1]&#34;, &#34;left_pose.im[2]&#34;,
         &#34;right_pose[0]&#34;, &#34;right_pose[1]&#34;, &#34;right_pose[2]&#34;, &#34;right_pose.re&#34;,
         &#34;right_pose.im[0]&#34;, &#34;right_pose.im[1]&#34;, &#34;right_pose.im[2]&#34;])

    if context_names is None:
        return T, P
    else:
        return T, P, context</code></pre>
</details>
</dd>
<dt id="movement_primitives.data.load_lasa"><code class="name flex">
<span>def <span class="ident">load_lasa</span></span>(<span>shape_idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Load demonstrations from LASA dataset.</p>
<p>The LASA dataset contains 2D handwriting motions recorded from a
Tablet-PC. It can be found <code>here
&lt;https://bitbucket.org/khansari/lasahandwritingdataset&gt;</code><em>
Take a look at the <code>detailed explanation
&lt;http://cs.stanford.edu/people/khansari/DSMotions#SEDS_Benchmark_Dataset&gt;</code></em>
for more information.</p>
<p>The following plot shows multiple demonstrations for the same shape.</p>
<div class="admonition plot">
<p class="admonition-title">Plot</p>
<p>import matplotlib.pyplot as plt
from movement_primitives.data import load_lasa
X, Xd, Xdd, dt, shape_name = load_lasa(0)
plt.figure()
plt.title(shape_name)
plt.plot(X[:, :, 0].T, X[:, :, 1].T)
plt.show()</p>
</div>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>shape_idx</code></strong> :&ensp;<code>int</code></dt>
<dd>Choose demonstrated shape, must be within range(30).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>T</code></strong> :&ensp;<code>array, shape (n_demos, n_steps)</code></dt>
<dd>Times</dd>
<dt><strong><code>X</code></strong> :&ensp;<code>array, shape (n_demos, n_steps, n_dims)</code></dt>
<dd>Positions</dd>
<dt><strong><code>Xd</code></strong> :&ensp;<code>array, shape (n_demos, n_steps, n_dims)</code></dt>
<dd>Velocities</dd>
<dt><strong><code>Xdd</code></strong> :&ensp;<code>array, shape (n_demos, n_steps, n_dims)</code></dt>
<dd>Accelerations</dd>
<dt><strong><code>dt</code></strong> :&ensp;<code>float</code></dt>
<dd>Time between steps</dd>
<dt><strong><code>shape_name</code></strong> :&ensp;<code>string</code></dt>
<dd>Name of the Matlab file from which we load the demonstrations
(without suffix).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_lasa(shape_idx):
    &#34;&#34;&#34;Load demonstrations from LASA dataset.

    The LASA dataset contains 2D handwriting motions recorded from a
    Tablet-PC. It can be found `here
    &lt;https://bitbucket.org/khansari/lasahandwritingdataset&gt;`_
    Take a look at the `detailed explanation
    &lt;http://cs.stanford.edu/people/khansari/DSMotions#SEDS_Benchmark_Dataset&gt;`_
    for more information.

    The following plot shows multiple demonstrations for the same shape.

    .. plot::

        import matplotlib.pyplot as plt
        from movement_primitives.data import load_lasa
        X, Xd, Xdd, dt, shape_name = load_lasa(0)
        plt.figure()
        plt.title(shape_name)
        plt.plot(X[:, :, 0].T, X[:, :, 1].T)
        plt.show()

    Parameters
    ----------
    shape_idx : int
        Choose demonstrated shape, must be within range(30).

    Returns
    -------
    T : array, shape (n_demos, n_steps)
        Times

    X : array, shape (n_demos, n_steps, n_dims)
        Positions

    Xd : array, shape (n_demos, n_steps, n_dims)
        Velocities

    Xdd : array, shape (n_demos, n_steps, n_dims)
        Accelerations

    dt : float
        Time between steps

    shape_name : string
        Name of the Matlab file from which we load the demonstrations
        (without suffix).
    &#34;&#34;&#34;
    dataset_path = get_common_dataset_path()
    if not os.path.isdir(dataset_path + &#34;lasa_data&#34;):  # pragma: no cover
        url = urlopen(LASA_URL)
        z = zipfile.ZipFile(io.BytesIO(url.read()))
        z.extractall(dataset_path)
        os.rename(dataset_path + z.namelist()[0],
                  dataset_path + &#34;lasa_data&#34; + os.sep)

    dataset_path += &#34;lasa_data&#34; + os.sep + &#34;DataSet&#34; + os.sep
    demos, shape_name = _load_from_matlab_file(dataset_path, shape_idx)
    X, Xd, Xdd, dt = _convert_demonstrations(demos)
    t = np.linspace(0, X.shape[1], X.shape[1])
    T = np.tile(t, (X.shape[0], 1))
    return T, X, Xd, Xdd, dt, shape_name</code></pre>
</details>
</dd>
<dt id="movement_primitives.data.load_mia_demo"><code class="name flex">
<span>def <span class="ident">load_mia_demo</span></span>(<span>filename, dt=0.01, ignore_columns=(), verbose=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Load a single demonstration for the Mia hand from csv.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the csv file.</dd>
<dt><strong><code>dt</code></strong> :&ensp;<code>float</code>, optional <code>(default: 0.01)</code></dt>
<dd>Time between steps.</dd>
<dt><strong><code>ignore_columns</code></strong> :&ensp;<code>list</code> or <code>tuple</code>, optional <code>(default: ())</code></dt>
<dd>Columns that should not be loaded.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code>, optional <code>(default: 0)</code></dt>
<dd>Verbosity level.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>T</code></strong> :&ensp;<code>array, shape (n_steps,)</code></dt>
<dd>Time steps</dd>
<dt><strong><code>P</code></strong> :&ensp;<code>array, shape (n_steps, 11 - len(ignore_columns))</code></dt>
<dd>Position of the palm frame, orientation of the palm frame as
quaternion, and joint angles. Pose of the palm frame is relative to
the manipulated object. Order of joint angles is "j_index_fle",
"j_mrl_fle", "j_thumb_fle", "j_thumb_opp".</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_mia_demo(filename, dt=0.01, ignore_columns=(), verbose=0):
    &#34;&#34;&#34;Load a single demonstration for the Mia hand from csv.

    Parameters
    ----------
    filename : str
        Name of the csv file.

    dt : float, optional (default: 0.01)
        Time between steps.

    ignore_columns : list or tuple, optional (default: ())
        Columns that should not be loaded.

    verbose : int, optional (default: 0)
        Verbosity level.

    Returns
    -------
    T : array, shape (n_steps,)
        Time steps

    P : array, shape (n_steps, 11 - len(ignore_columns))
        Position of the palm frame, orientation of the palm frame as
        quaternion, and joint angles. Pose of the palm frame is relative to
        the manipulated object. Order of joint angles is &#34;j_index_fle&#34;,
        &#34;j_mrl_fle&#34;, &#34;j_thumb_fle&#34;, &#34;j_thumb_opp&#34;.
    &#34;&#34;&#34;
    trajectory = pd.read_csv(filename)
    T = np.arange(0.0, dt * len(trajectory), dt)
    if len(T) != len(trajectory):
        T = T[:len(trajectory)]

    ALL_COLUMNS = [
        &#34;base_x&#34;, &#34;base_y&#34;, &#34;base_z&#34;, &#34;base_qw&#34;, &#34;base_qx&#34;, &#34;base_qy&#34;,
        &#34;base_qz&#34;, &#34;j_index_fle&#34;, &#34;j_mrl_fle&#34;, &#34;j_thumb_fle&#34;, &#34;j_thumb_opp&#34;]
    # quadratic complexity; since order is relevant, we cannot use a set
    # difference
    columns = [c for c in ALL_COLUMNS if c not in ignore_columns]
    if verbose &gt;= 2:
        tqdm.write(&#34;Loading columns: [%s]&#34; % &#34;, &#34;.join(columns))

    P = trajectory[columns].to_numpy()
    return T, P</code></pre>
</details>
</dd>
<dt id="movement_primitives.data.load_rh5_demo"><code class="name flex">
<span>def <span class="ident">load_rh5_demo</span></span>(<span>filename, verbose=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Load a single demonstration from the RH5 robot from csv.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the csv file.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code>, optional <code>(default: 0)</code></dt>
<dd>Verbosity level</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>T</code></strong> :&ensp;<code>array, shape (n_steps,)</code></dt>
<dd>Time steps</dd>
<dt><strong><code>P</code></strong> :&ensp;<code>array, shape (n_steps, 14)</code></dt>
<dd>Dual arm trajectories represented by position of the left arm,
orientation quaternion of the left arm, position of the right arm,
and orientation quaternion of the right arm.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_rh5_demo(filename, verbose=0):
    &#34;&#34;&#34;Load a single demonstration from the RH5 robot from csv.

    Parameters
    ----------
    filename : str
        Name of the csv file.

    verbose : int, optional (default: 0)
        Verbosity level

    Returns
    -------
    T : array, shape (n_steps,)
        Time steps

    P : array, shape (n_steps, 14)
        Dual arm trajectories represented by position of the left arm,
        orientation quaternion of the left arm, position of the right arm,
        and orientation quaternion of the right arm.
    &#34;&#34;&#34;
    if verbose:
        tqdm.write(&#34;Loading &#39;%s&#39;&#34; % filename)
    trajectory = pd.read_csv(filename, sep=&#34; &#34;)
    PREFIX_LEFT = &#34;rh5_left_arm_posture_ctrl\.current_feedback\.pose\.&#34;
    PREFIX_RIGHT = &#34;rh5_right_arm_posture_ctrl\.current_feedback\.pose\.&#34;
    patterns = [
        &#34;time\.microseconds&#34;,
        f&#34;{PREFIX_LEFT}position\.data.*&#34;,
        f&#34;{PREFIX_LEFT}orientation\.re.*&#34;,
        f&#34;{PREFIX_LEFT}orientation\.im.*&#34;,
        f&#34;{PREFIX_RIGHT}position\.data.*&#34;,
        f&#34;{PREFIX_RIGHT}orientation\.re.*&#34;,
        f&#34;{PREFIX_RIGHT}orientation\.im.*&#34;]
    columns = mocap.pandas_utils.match_columns(trajectory, patterns)
    trajectory = trajectory[columns]

    group_rename = {
        &#34;(time\.microseconds)&#34;: &#34;Time&#34;,
        f&#34;({PREFIX_LEFT}position\.data).*&#34;: &#34;left_pose&#34;,
        f&#34;({PREFIX_LEFT}orientation).*&#34;: &#34;left_pose&#34;,
        f&#34;({PREFIX_RIGHT}position\.data).*&#34;: &#34;right_pose&#34;,
        f&#34;({PREFIX_RIGHT}orientation).*&#34;: &#34;right_pose&#34;
    }
    trajectory = mocap.pandas_utils.rename_stream_groups(trajectory, group_rename)

    trajectory[&#34;Time&#34;] = trajectory[&#34;Time&#34;] / 1e6
    trajectory[&#34;Time&#34;] -= trajectory[&#34;Time&#34;].iloc[0]
    T = trajectory[&#34;Time&#34;].to_numpy()

    P = mocap.array_from_dataframe(
        trajectory,
        [&#34;left_pose[0]&#34;, &#34;left_pose[1]&#34;, &#34;left_pose[2]&#34;, &#34;left_pose.re&#34;,
         &#34;left_pose.im[0]&#34;, &#34;left_pose.im[1]&#34;, &#34;left_pose.im[2]&#34;,
         &#34;right_pose[0]&#34;, &#34;right_pose[1]&#34;, &#34;right_pose[2]&#34;, &#34;right_pose.re&#34;,
         &#34;right_pose.im[0]&#34;, &#34;right_pose.im[1]&#34;, &#34;right_pose.im[2]&#34;])

    return T, P</code></pre>
</details>
</dd>
<dt id="movement_primitives.data.smooth_dual_arm_trajectories_pq"><code class="name flex">
<span>def <span class="ident">smooth_dual_arm_trajectories_pq</span></span>(<span>Ps, median_filter_window=5)</span>
</code></dt>
<dd>
<div class="desc"><p>Make orientation representation smooth.</p>
<p>Note that the argument Ps will be manipulated and the function does not
return anything.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>Ps</code></strong> :&ensp;<code>list</code></dt>
<dd>List of dual arm trajectories represented by position of the left arm,
orientation quaternion of the left arm, position of the right arm,
and orientation quaternion of the right arm.</dd>
<dt><strong><code>median_filter_window</code></strong> :&ensp;<code>int</code>, optional <code>(default: 5)</code></dt>
<dd>Window size of the median filter</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def smooth_dual_arm_trajectories_pq(Ps, median_filter_window=5):
    &#34;&#34;&#34;Make orientation representation smooth.

    Note that the argument Ps will be manipulated and the function does not
    return anything.

    Parameters
    ----------
    Ps : list
        List of dual arm trajectories represented by position of the left arm,
        orientation quaternion of the left arm, position of the right arm,
        and orientation quaternion of the right arm.

    median_filter_window : int, optional (default: 5)
        Window size of the median filter
    &#34;&#34;&#34;
    for P in Ps:
        P[:, 3:7] = mocap.cleaning.smooth_quaternion_trajectory(P[:, 3:7])
        P[:, 10:] = mocap.cleaning.smooth_quaternion_trajectory(P[:, 10:])
        P[:, :] = mocap.cleaning.median_filter(
            P, window_size=median_filter_window)</code></pre>
</details>
</dd>
<dt id="movement_primitives.data.smooth_single_arm_trajectories_pq"><code class="name flex">
<span>def <span class="ident">smooth_single_arm_trajectories_pq</span></span>(<span>Ps, median_filter_window=5)</span>
</code></dt>
<dd>
<div class="desc"><p>Make orientation representation smooth.</p>
<p>Note that the argument Ps will be manipulated and the function does not
return anything.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>Ps</code></strong> :&ensp;<code>list</code></dt>
<dd>List of single arm trajectories represented by position of the arm and
orientation quaternion of the arm.</dd>
<dt><strong><code>median_filter_window</code></strong> :&ensp;<code>int</code>, optional <code>(default: 5)</code></dt>
<dd>Window size of the median filter</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def smooth_single_arm_trajectories_pq(Ps, median_filter_window=5):
    &#34;&#34;&#34;Make orientation representation smooth.

    Note that the argument Ps will be manipulated and the function does not
    return anything.

    Parameters
    ----------
    Ps : list
        List of single arm trajectories represented by position of the arm and
        orientation quaternion of the arm.

    median_filter_window : int, optional (default: 5)
        Window size of the median filter
    &#34;&#34;&#34;
    for P in Ps:
        P[:, 3:7] = mocap.cleaning.smooth_quaternion_trajectory(P[:, 3:7])
        P[:, :] = mocap.cleaning.median_filter(
            P, window_size=median_filter_window)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="movement_primitives" href="../index.html">movement_primitives</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="movement_primitives.data.generate_1d_trajectory_distribution" href="#movement_primitives.data.generate_1d_trajectory_distribution">generate_1d_trajectory_distribution</a></code></li>
<li><code><a title="movement_primitives.data.generate_minimum_jerk" href="#movement_primitives.data.generate_minimum_jerk">generate_minimum_jerk</a></code></li>
<li><code><a title="movement_primitives.data.load_kuka_dataset" href="#movement_primitives.data.load_kuka_dataset">load_kuka_dataset</a></code></li>
<li><code><a title="movement_primitives.data.load_kuka_demo" href="#movement_primitives.data.load_kuka_demo">load_kuka_demo</a></code></li>
<li><code><a title="movement_primitives.data.load_lasa" href="#movement_primitives.data.load_lasa">load_lasa</a></code></li>
<li><code><a title="movement_primitives.data.load_mia_demo" href="#movement_primitives.data.load_mia_demo">load_mia_demo</a></code></li>
<li><code><a title="movement_primitives.data.load_rh5_demo" href="#movement_primitives.data.load_rh5_demo">load_rh5_demo</a></code></li>
<li><code><a title="movement_primitives.data.smooth_dual_arm_trajectories_pq" href="#movement_primitives.data.smooth_dual_arm_trajectories_pq">smooth_dual_arm_trajectories_pq</a></code></li>
<li><code><a title="movement_primitives.data.smooth_single_arm_trajectories_pq" href="#movement_primitives.data.smooth_single_arm_trajectories_pq">smooth_single_arm_trajectories_pq</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>